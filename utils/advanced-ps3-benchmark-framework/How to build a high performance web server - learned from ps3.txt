How to build a high performance web server
                        ---- what we learned from ps3

1. Eliminating long-blocked IO

The starting code of ps3 uses io::read_whole_file(Path) to get the whole file data, than write it to a socket stream. However, read_whole_file() takes very long time to return when the requested file is large, consequently, it blocks the socket I/O for a long time. If we construct a loop to read small chunks of file data and write it to the socket stream immediately, the network resource can be utilized much better.

## Modifications on the code:
    zhtta-v1
    * Added a file chunk buffer whose size can be specified by program arguement.
    * Rewrote new code to replace io::read_whole_file(Path).

## Preliminary result
$ httperf --server localhost --port 4414 --rate 500 --num-conns 1000
                                                    Duration Time (s)   Average Response Time (ms)
zhtta-starting-code                                 823.545             352412.1
zhtta-v1 (chunk buffer size of 512000 bytes)        131.198              70074.4

The improvement on performance was really significant after we changed the disk IO code!

## Discussion
    * Which buffer size is the best? Figure it out by experiment.
        1KB, 10KB, 50KB, 100KB, 512KB, 1MB, 2MB, 4MB, 10MB, 50MB, 100MB, 512MB (should be the same as io::read_whole_file(Path))
      - Buffer size too small => too many rounds of reading data into chunk buffer.
      - Buffer size too large => long latency in each chunk reading operation, occupy too much memory.
    
    * Which API in Rust is betterr? Why?
        Trait std::io::ReaderUtil  fn read_bytes(&self, len: uint) -> ~[u8];
        Trait std::io::Reader      fn read(&self, bytes: &mut [u8], len: uint) -> uint;
      Answer: The second one can be faster, because Rust can avoid allocating memory as the buffer in each iteration.
    
    * Why is io::read_whole_file(Path) so slow? It performed much worse even if we set a similar chunk buffer size.
      Answer: The reason could be found in the core part of the API:
                while !self.eof() { bytes.push_all(self.read_bytes(2048u)); }
                
              vec::push_all() copies the new chunk data to the vector byte by byte, which is pretty slow.
              ReaderUtil::read_bytes(2048u) returns an extra small chunk in each iteration, and it needs to allocate memory in each iteration, which is very very slow.


2. Improving concurrency

The ps3 starting code only has one responder task that takes requests from queue and do the response. Obviously, we can spawn more responder tasks to increase the resource utilization.

## Modifications on the code:
    zhtta-v2
    * Added a loop to spawn several responder tasks.
    * Cloned shared arcs for each spawned task.

## Preliminary result
$ httperf --server localhost --port 4414 --rate 500 --num-conns 1000
                                                    Duration Time (s)   Average Response Time (ms)
zhtta-starting-code                                 823.545             352412.1
zhtta-v1 (chunk buffer size of 512000 bytes)        131.198              70074.4
zhtta-v2 (5 concurrent responder tasks)              48.079              20828.4

The improvement on performance was really significant after we added more concurrent responder tasks.

## Discussion
    * The higher concurrency, the better?
      Answer:
        No. Higher concurrency also means more resource are needed to maintain and manage the concurrent tasks.
        Here's an extreme example:
            single-task server, which has no concurrency
            zhttpto server, which has unlimited concurrency
        But, single-task server performs better in benchmark!
        
    * Which level of concurrency is the best in zhtta? Design and conduct an experiement to figure it out.
        1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024



3. SPT scheduling

The ps3 starting code schedules the http requests in FIFO manner. Obviously, if the earlier requests take too long to response, the waiting time of the latter requests as well as the average waiting time will increase. A Shortest Processing Time first (SPT) scheduling may help to minimize the average waiting time. However, the advantage of SPT is not always significant since it strongly depends on the request sequence. Sometimes it performs even worse than FIFO due to the extra significant overhead caused by potential bad implementation.

## Modifications on the code:
    zhtta-v3
    * Added a new data structure to sort the processing time of each request.

## Preliminary result
$ httperf --server localhost --port 4414 --rate 500 --num-conns 1000
                                                    Duration Time (s)   Average Response Time (ms)
zhtta-starting-code                                 823.545             352412.1
zhtta-v1 (chunk buffer size of 512000 bytes)        131.198              70074.4
zhtta-v2 (5 concurrent responding tasks)             48.079              20828.4
zhtta-v3 (SPT scheduling)                            47.206	             19660.1

The improvement on performance was not so significant after we replaced FIFO scheduling with SPT scheduling.

## Discussion
    * Why SPT scheduling didn't make much difference in the preliminary result? In which scenario can SPT sheduling show its significance?
      Answer: SPT scheduling will show its power when the earlier long requests occupy most of the network resource, and force the later short requests to wait in FIFO manner. It is more than significant if you run the test on a low-bandwidth network connection. (Actually, the SRPT paper also assumes the bottle neck is the network bandwidth.) According to the result of iPerf, The default TCP bandwidth of the loopback interface on my laptop is around 20Gbps. Such extremely high network bandwidth makes the power of SPT scheduling less significant. 
      Hopefully, it's easy to limit the bandwitdh of network interface on Linux. You can do further interesting benchmark to verify the efficiency of SPT scheduling on a low-bandwidth network connection.
      # Limit the bandwith of loopback to 80Mbps
      sudo tc qdisc add dev lo root handle 1: htb default 12 
      sudo tc class add dev lo parent 1:1 classid 1:12 htb rate 10240kbps ceil 10240kbps
      # Remove the limitation
      sudo tc qdisc del dev lo root handle 1: htb default 12 
    

4. File caching

Disk IO is often (if not always) a performance bottleneck in various systems. One of the most useful solutions is memory caching. There're three approaches to implement file caching.
    - VFS caching:
        pros: a free feature of Linux.
        cons: you cannot control the cache item replacement.
              it could be affected by other programs
              it caches everyting whatever you want or not.
    - Ramdisk caching:
        pros: a free feature of Linux.
              you can create an application-exclusive ramdisk.
              you can control the cache item by moving files between ramdisk and the real disk.
        cons: it needs root privilege to execute several system commands.
    - Application-layer caching:
        pros: you can customize everything, such as the replacement algorithm.
        cons: it needs more complicated code to implement.


## Modifications on the code:
    zhtta
    * Implemented an application-layer cache management module.
    
## Preliminary result
$ httperf --server localhost --port 4414 --rate 500 --num-conns 1000
                                                    Duration Time (s)   Average Response Time (ms)
zhtta-starting-code                                 823.545             352412.1
zhtta-v1 (chunk buffer size of 512000 bytes)        131.198              70074.4
zhtta-v2 (5 concurrent responding tasks)             48.079              20828.4
zhtta-v3 (SPT scheduling)                            47.206	             19660.1
zhtta    (poor application-layer caching)            79.54	             40208.3

## Discussion
    * Why the performance got worse after adding the application-layer caching?
      Answer: It's because the bad implementation. Some code in the application-layer caching module blocks the zhtta responder tasks. 
      
    * What's the upper bound of main memory caching performance? Get it by ramdisk!
      Ramdisk could allocate a block of RAM and mount it as a disk. All of the file operations on the ramdisk actually take place on the main memory, and all the data will be erased after you restart the computer. You can eliminate the bottleneck of disk IO if you run zhtta on a ramdisk.
      Here's the commands you need to create a 1GB ramdisk.
        $ mkdir -p /home/student/www-ram
        $ sudo mount -t tmpfs -o size=1024M tmpfs /home/student/www-ram
      On my computer, however, Ramdisk makes little difference, because VFS caching had been taken advatage of the 8GB memory.
    
    
* What're the potential performance bottlenecks in improper implementation?
 - Put unnecessary code in critical sections, especially the IO operations with long latency.
 - New tasks were blocked by IO operation
 - Busy waiting for critical resource
 - ...

